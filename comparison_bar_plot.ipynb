{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from GombNet.networks import *\n",
    "from GombNet.loss_func import GombinatorialLoss, DiceLoss\n",
    "from GombNet.utils import *\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.filters import threshold_otsu\n",
    "%matplotlib ipympl\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/austin/Documents/GitHub/DataGenSTEM/DataGenSTEM')\n",
    "import data_generator as dg\n",
    "\n",
    "from scipy.ndimage import gaussian_filter, center_of_mass\n",
    "from skimage.feature import blob_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.family'] = 'Times New Roman'\n",
    "plt.rcParams['font.size'] = 12 \n",
    "plt.rcParams['xtick.labelsize'] = 12\n",
    "plt.rcParams['ytick.labelsize'] = 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_folder = '/Users/austin/Desktop/Gomb-Net aux files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gomb_loss_history = np.load(shared_folder + '/Pretrained_models/TwoLeggedGraphene256.pthloss_history.npz')\n",
    "gomb_train_loss = gomb_loss_history['train_loss_history']\n",
    "gomb_val_loss = gomb_loss_history['val_loss_history']\n",
    "\n",
    "unet_loss_history = np.load(shared_folder + '/Pretrained_models/BasicUNet256_nodrop.pthloss_history.npz')\n",
    "unet_train_loss = unet_loss_history['train_loss_history']\n",
    "unet_val_loss = unet_loss_history['val_loss_history']\n",
    "\n",
    "unet_gomb_loss_history = np.load(shared_folder + '/Pretrained_models/BasicUNet256.pthloss_history.npz')\n",
    "unet_gomb_train_loss = unet_gomb_loss_history['train_loss_history']\n",
    "unet_gomb_val_loss = unet_gomb_loss_history['val_loss_history']\n",
    "\n",
    "fig, axs = plt.subplots(3, 1, figsize=(5, 10))\n",
    "\n",
    "axs[0].plot(unet_train_loss, label='train', color = '#1f77b4')\n",
    "axs[0].plot(unet_val_loss, label='val', color = '#d62728')\n",
    "axs[0].set_xlim(0, 29)\n",
    "\n",
    "axs[1].plot(unet_gomb_train_loss, label='train', color = '#1f77b4')\n",
    "axs[1].plot(unet_gomb_val_loss, label='val', color = '#d62728')\n",
    "axs[1].set_xlim(0, 99)\n",
    "\n",
    "axs[2].plot(gomb_train_loss, label='training', color = '#1f77b4')\n",
    "axs[2].plot(gomb_val_loss, label='validation', color = '#d62728')\n",
    "axs[2].set_xlim(0, 29)\n",
    "\n",
    "for ax in axs:\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Loss')\n",
    "    ax.legend(loc='upper right')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.savefig('loss_history', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataloaders\n",
    "images_dir = str(shared_folder + '/Graphene_dataset/images')\n",
    "labels_dir = str(shared_folder + '/Graphene_dataset/labels')\n",
    "train_loader, val_loader, test_loader = get_dataloaders(images_dir, labels_dir, batch_size = 1, val_split=0.2, test_split=0.1, seed = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_iter = 4 # this is a nice one\n",
    "test = test_loader.dataset[test_iter][0].unsqueeze(0)\n",
    "gt = test_loader.dataset[test_iter][1]\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "ax[0].imshow(test[0, 0], cmap='gray')\n",
    "ax[0].set_title('Input')\n",
    "\n",
    "titles = ['L1: C', 'L2: C']\n",
    "for i in range(2):\n",
    "    ax[i+1].imshow(gt[i].cpu().numpy(), cmap='gray')\n",
    "    ax[i+1].set_title(titles[i])\n",
    "for a in ax:\n",
    "    a.axis('off')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_channels = 1\n",
    "num_classes = 2\n",
    "num_filters = [32, 64, 128, 256]\n",
    "threshold = 0\n",
    "# test = gaussian_filter(test, sigma=1)\n",
    "test -= test.min()\n",
    "test /= test.max()\n",
    "test = torch.tensor(test).float()\n",
    "\n",
    "predictions = []\n",
    "# Unet w Dice Loss\n",
    "path = str(shared_folder + '/Pretrained_models/BasicUNet256_nodrop.pth')\n",
    "\n",
    "model = Unet(input_channels, num_classes, num_filters, dropout = 0.2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss = DiceLoss(alpha=2)\n",
    "checkpoint = torch.load(path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(test)\n",
    "    pred = pred.squeeze(0)\n",
    "    pred = pred.cpu().numpy()\n",
    "    # pred = (pred > threshold)\n",
    "    predictions.append(pred)\n",
    "\n",
    "\n",
    "# Unet w Gomb Loss\n",
    "path = str(shared_folder + '/Pretrained_models/BasicUNet256.pth')\n",
    "\n",
    "model = Unet(input_channels, num_classes, num_filters, dropout = 0.2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss = GombinatorialLoss(group_size = num_classes//2, loss = 'Dice', epsilon=1e-6, class_weights = None, alpha=2)\n",
    "checkpoint = torch.load(path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(test)\n",
    "    pred = pred.squeeze(0)\n",
    "    pred = pred.cpu().numpy()\n",
    "    # pred = (pred > threshold)\n",
    "    predictions.append(pred)\n",
    "\n",
    "\n",
    "# GombNet\n",
    "path = str(shared_folder + '/Pretrained_models/TwoLeggedGraphene256.pth')\n",
    "\n",
    "model = TwoLeggedUnet(input_channels, num_classes, num_filters, dropout = 0.2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss = GombinatorialLoss(group_size = num_classes//2, loss = 'Dice', epsilon=1e-6, class_weights = None, alpha=2)\n",
    "checkpoint = torch.load(path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    pred = model(test)\n",
    "    pred = pred.squeeze(0)\n",
    "    pred = pred.cpu().numpy()\n",
    "    # pred = (pred > threshold)\n",
    "    predictions.append(pred)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['UNet w Dice Loss', 'UNet w Gomb Loss', 'GombNet']\n",
    "colors = ['viridis', 'plasma']\n",
    "for idx, p in enumerate(predictions):\n",
    "    fig.suptitle(names[idx])\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(10, 5))\n",
    "    ax[0].imshow(test[0, 0].cpu().numpy(), cmap='gray')\n",
    "    ax[0].set_title('Input')\n",
    "\n",
    "    for i in range(2):\n",
    "        ax[i+1].imshow(p[i], cmap=colors[i])\n",
    "    \n",
    "    for a in ax:\n",
    "        a.axis('off')\n",
    "    fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try a regular blob finder for comparison\n",
    "blob_im = test.squeeze().cpu().numpy()\n",
    "\n",
    "blobs = blob_log(blob_im, min_sigma=1, max_sigma=20, num_sigma=5, threshold=0.1)\n",
    "blobs_com = [center_of_mass(blob_im, blobs[i, 0], blobs[i, 1]) for i in range(blobs.shape[0])]\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(blob_im, cmap='gray')\n",
    "plt.scatter(blobs[:, 1], blobs[:, 0], c='r', s=20)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, pred in enumerate(predictions):\n",
    "    fig, ax = plt.subplots(1, 3, figsize=(20, 8))\n",
    "    fig.suptitle(names[idx])\n",
    "    ax[0].imshow(test[0, 0].cpu().numpy(), cmap='gray')\n",
    "    ax[0].set_title('Input')\n",
    "\n",
    "    colors = ['r', 'g']\n",
    "    for i in range(2):\n",
    "        ax[i+1].imshow(blob_im, cmap='gray', vmin=-1,vmax=0)\n",
    "        blobs = blob_log(pred[i], min_sigma=3, max_sigma=20, num_sigma=10, threshold=0.2)\n",
    "        blobs_co1 = [center_of_mass(pred[i,0], blobs[j, 0], blobs[j, 1]) for j in range(blobs.shape[0])]\n",
    "        ax[1].scatter(blobs[:, 1], blobs[:, 0], c=colors[i], s=80, alpha = 0.8, edgecolors='k', linewidth=0.5)\n",
    "\n",
    "    for a in ax:\n",
    "        a.axis('off')\n",
    "        a.set_ylim(0, 256)\n",
    "        a.set_xlim(0, 256)\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bar plot below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(pred, gt):\n",
    "    intersection = np.logical_and(pred, gt).sum()\n",
    "    union = np.logical_or(pred, gt).sum()\n",
    "    return intersection / union\n",
    "\n",
    "def dice_coefficient(pred, gt):\n",
    "    intersection = np.logical_and(pred, gt).sum()\n",
    "    return 2 * intersection / (pred.sum() + gt.sum())\n",
    "\n",
    "# Function to count the number of trainable parameters\n",
    "def count_trainable_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random guessing benchmark\n",
    "pwa_total = 0\n",
    "dice_total = 0\n",
    "IoU_total = 0\n",
    "\n",
    "for i in range(len(test_loader)):\n",
    "    gt = test_loader.dataset[i][1].numpy()  # Convert to numpy array\n",
    "    \n",
    "    # Random guessing\n",
    "    prediction = np.random.randint(0, 2, gt.shape)\n",
    "\n",
    "    pwa_original = np.sum(prediction == gt) / np.prod(gt.shape)\n",
    "    dice_original = dice_coefficient(prediction, gt)\n",
    "    iou_original = iou(prediction, gt)\n",
    "    \n",
    "    pwa_total += pwa_original\n",
    "    dice_total += dice_original\n",
    "    IoU_total += iou_original\n",
    "\n",
    "pwa_total /= len(test_loader)\n",
    "dice_total /= len(test_loader)\n",
    "IoU_total /= len(test_loader)\n",
    "\n",
    "acc_random = [pwa_total, dice_total, IoU_total]\n",
    "print(\"Random\")\n",
    "print(f\"Pixel-wise Accuracy: {pwa_total}\")\n",
    "print(f\"Mean Dice Coefficient: {dice_total}\")\n",
    "print(f\"Mean IoU: {IoU_total}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular Unet Benchmark\n",
    "input_channels = 1\n",
    "num_classes = 2\n",
    "num_filters = [32, 64, 128, 256]\n",
    "\n",
    "model = Unet(input_channels, num_classes, num_filters, dropout = 0.2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss = DiceLoss(alpha=2)\n",
    "\n",
    "model_path = '/Users/austin/Documents/GitHub/GombNet/trained_models/BasicUNet256_nodrop.pth'\n",
    "checkpoint = torch.load(model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "pwa_total = 0\n",
    "dice_total = 0\n",
    "IoU_total = 0\n",
    "\n",
    "# Calculate the accuracy\n",
    "for i in range(len(test_loader)):\n",
    "    test = test_loader.dataset[i][0].unsqueeze(0)\n",
    "    gt = test_loader.dataset[i][1].numpy()  # Convert to numpy array\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        probability = model(test)\n",
    "        prediction = torch.sigmoid(probability)  # Use torch.sigmoid instead of F.sigmoid (deprecated)\n",
    "    \n",
    "    probability = probability.squeeze().cpu().numpy()\n",
    "    prediction = prediction.squeeze().cpu().numpy()\n",
    "\n",
    "    threshold = threshold_otsu(prediction)\n",
    "    prediction = (prediction > threshold).astype(float)\n",
    "    \n",
    "    # Calculate metrics for original and switched ground truths\n",
    "    pwa_original = np.sum(prediction == gt) / np.prod(gt.shape)\n",
    "    dice_original = dice_coefficient(prediction, gt)\n",
    "    iou_original = iou(prediction, gt)\n",
    "    \n",
    "    # There is not combinatorial here\n",
    "    pwa_total += pwa_original\n",
    "    dice_total += dice_original\n",
    "    IoU_total += iou_original\n",
    "\n",
    "# Calculate the average for each metric\n",
    "pwa_total /= len(test_loader)\n",
    "dice_total /= len(test_loader)\n",
    "IoU_total /= len(test_loader)\n",
    "\n",
    "acc_UNet = [pwa_total, dice_total, IoU_total]\n",
    "\n",
    "print(\"UNet\")\n",
    "print(f\"Pixel-wise Accuracy: {pwa_total}\")\n",
    "print(f\"Mean Dice Coefficient: {dice_total}\")\n",
    "print(f\"Mean IoU: {IoU_total}\")\n",
    "\n",
    "# Get the number of trainable parameters\n",
    "num_trainable_params = count_trainable_parameters(model)\n",
    "print(f\"Number of trainable parameters: {num_trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regular Unet Benchmark\n",
    "input_channels = 1\n",
    "num_classes = 2\n",
    "num_filters = [32, 64, 128, 256]\n",
    "\n",
    "model = Unet(input_channels, num_classes, num_filters, dropout = 0.2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss = DiceLoss(alpha=2)\n",
    "\n",
    "model_path = '/Users/austin/Documents/GitHub/GombNet/trained_models/BasicUNet256.pth'\n",
    "checkpoint = torch.load(model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "pwa_total = 0\n",
    "dice_total = 0\n",
    "IoU_total = 0\n",
    "\n",
    "# Calculate the accuracy\n",
    "for i in range(len(test_loader)):\n",
    "    test = test_loader.dataset[i][0].unsqueeze(0)\n",
    "    gt = test_loader.dataset[i][1].numpy()  # Convert to numpy array\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        probability = model(test)\n",
    "        prediction = torch.sigmoid(probability)  # Use torch.sigmoid instead of F.sigmoid (deprecated)\n",
    "    \n",
    "    probability = probability.squeeze().cpu().numpy()\n",
    "    prediction = prediction.squeeze().cpu().numpy()\n",
    "\n",
    "    threshold = threshold_otsu(prediction)\n",
    "    prediction = (prediction > threshold).astype(float)\n",
    "    \n",
    "    # Calculate metrics for original and switched ground truths\n",
    "    pwa_original = np.sum(prediction == gt) / np.prod(gt.shape)\n",
    "    dice_original = dice_coefficient(prediction, gt)\n",
    "    iou_original = iou(prediction, gt)\n",
    "    \n",
    "    # There is not combinatorial here\n",
    "    pwa_total += pwa_original\n",
    "    dice_total += dice_original\n",
    "    IoU_total += iou_original\n",
    "\n",
    "# Calculate the average for each metric\n",
    "pwa_total /= len(test_loader)\n",
    "dice_total /= len(test_loader)\n",
    "IoU_total /= len(test_loader)\n",
    "\n",
    "acc_UNet_gomb = [pwa_total, dice_total, IoU_total]\n",
    "\n",
    "print(\"UNet w Gomb\")\n",
    "print(f\"Pixel-wise Accuracy: {pwa_total}\")\n",
    "print(f\"Mean Dice Coefficient: {dice_total}\")\n",
    "print(f\"Mean IoU: {IoU_total}\")\n",
    "\n",
    "# Get the number of trainable parameters\n",
    "num_trainable_params = count_trainable_parameters(model)\n",
    "print(f\"Number of trainable parameters: {num_trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GombNet\n",
    "input_channels = 1\n",
    "num_classes = 2\n",
    "num_filters = [32, 64, 128, 256]\n",
    "\n",
    "model = TwoLeggedUnet(input_channels, num_classes, num_filters, dropout = 0.2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss = GombinatorialLoss(group_size = num_classes//2, loss = 'Dice', epsilon=1e-6, class_weights = None, alpha=2)\n",
    "\n",
    "model_path = '/Users/austin/Documents/GitHub/GombNet/trained_models/TwoLeggedGraphene256.pth'\n",
    "checkpoint = torch.load(model_path)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "model.eval()\n",
    "\n",
    "pwa_total = 0\n",
    "dice_total = 0\n",
    "IoU_total = 0\n",
    "\n",
    "# Calculate the accuracy\n",
    "for i in range(len(test_loader)):\n",
    "    test = test_loader.dataset[i][0].unsqueeze(0)\n",
    "    gt = test_loader.dataset[i][1].numpy()  # Convert to numpy array\n",
    "    \n",
    "    # Switch ground truth layers\n",
    "    gt_switched = np.flip(gt, axis=0)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        probability = model(test)\n",
    "        prediction = torch.sigmoid(probability)  # Use torch.sigmoid instead of F.sigmoid (deprecated)\n",
    "    \n",
    "    probability = probability.squeeze().cpu().numpy()\n",
    "    prediction = prediction.squeeze().cpu().numpy()\n",
    "\n",
    "    threshold = threshold_otsu(prediction)\n",
    "    prediction = (prediction > threshold).astype(float)\n",
    "    \n",
    "    # Calculate metrics for original and switched ground truths\n",
    "    pwa_original = np.sum(prediction == gt) / np.prod(gt.shape)\n",
    "    pwa_switched = np.sum(prediction == gt_switched) / np.prod(gt_switched.shape)\n",
    "    \n",
    "    dice_original = dice_coefficient(prediction, gt)\n",
    "    dice_switched = dice_coefficient(prediction, gt_switched)\n",
    "    \n",
    "    iou_original = iou(prediction, gt)\n",
    "    iou_switched = iou(prediction, gt_switched)\n",
    "    \n",
    "    # Take the highest value for each metric\n",
    "    pwa_total += max(pwa_original, pwa_switched)\n",
    "    dice_total += max(dice_original, dice_switched)\n",
    "    IoU_total += max(iou_original, iou_switched)\n",
    "\n",
    "# Calculate the average for each metric\n",
    "pwa_total /= len(test_loader)\n",
    "dice_total /= len(test_loader)\n",
    "IoU_total /= len(test_loader)\n",
    "\n",
    "acc_GombNet = [pwa_total, dice_total, IoU_total]\n",
    "\n",
    "print(\"GombNet\")\n",
    "print(f\"Pixel-wise Accuracy: {pwa_total}\")\n",
    "print(f\"Mean Dice Coefficient: {dice_total}\")\n",
    "print(f\"Mean IoU: {IoU_total}\")\n",
    "\n",
    "# Get the number of trainable parameters\n",
    "num_trainable_params = count_trainable_parameters(model)\n",
    "print(f\"Number of trainable parameters: {num_trainable_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#1f77b4', 'green', '#d62728', 'purple', '#ff7f0e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['#1f77b4', 'green', '#d62728', 'purple', '#ff7f0e']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ['Pixel-wise Accuracy', 'Mean Dice Coefficient', 'Mean IoU']\n",
    "bar_width = 0.2\n",
    "space_between_bars = 0.03\n",
    "\n",
    "index = np.arange(len(metrics))\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "\n",
    "# Adjusting the positions for uniform spacing\n",
    "positions = [-1.5 * (bar_width + space_between_bars), \n",
    "             -0.5 * (bar_width + space_between_bars), \n",
    "              0.5 * (bar_width + space_between_bars), \n",
    "              1.5 * (bar_width + space_between_bars)]\n",
    "\n",
    "# Plot bars for Random\n",
    "bar1 = ax.bar(index + positions[0], acc_random, bar_width, label='Random Guessing', color='#1f77b4')\n",
    "\n",
    "# Plot bars for UNet\n",
    "bar2 = ax.bar(index + positions[1], acc_UNet, bar_width, label='U-Net w Dice Loss', color='green')\n",
    "\n",
    "# Plot bars for UNet with Gomb loss\n",
    "bar3 = ax.bar(index + positions[2], acc_UNet_gomb, bar_width, label='U-Net w Gomb Loss', color='#d62728')\n",
    "\n",
    "# Plot bars for GombNet\n",
    "bar4 = ax.bar(index + positions[3], acc_GombNet, bar_width, label='Gomb-Net', color='#ff7f0e')\n",
    "\n",
    "# Add labels, title, and legend\n",
    "ax.set_ylabel('Values')\n",
    "ax.set_xticks(index)\n",
    "ax.set_xticklabels(metrics)\n",
    "ax.legend()\n",
    "\n",
    "# Save and show the plot\n",
    "plt.savefig('GombNet_vs_UNet.png', dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-nightly",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
